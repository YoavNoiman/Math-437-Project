---
title: "Replace this with an interesting title"
---





## Motivation and Context





```{r}
#| label: do this first
#| echo: false
#| message: false

here::i_am("Final_Project_Text_And_Code.qmd")
```





This section describes what you are investigating in your project and why you are investigating it. You should provide enough contextual background and information that someone with a limited background can understand the broad outlines of the topic being investigated.

I am investigating attendance at NFL games because it is interesting to delve into the many factors that play into why a person would go to a stadium rather than simply watch from home. The time of day, date, loyalty to a team, cost, and rivalries may all play a role. There are also other monetary reasons one should consider investigating future attendance. For instance, given a predicted increase, which isn't possible due to stadium limitations, renovating stadiums for additional seats may become a priority. In addition, there are dynamic reasons, such as ticket prices and the number of staff, which can change depending on predicted attendance.

The background to understand NFL game attendance is the locations of stadiums and the popularity of teams. While how the game is played is interesting, it isn't vital to the analysis as long as we know that higher scores are better. There is, however, a simple rating system where 0 is an average team, with above zero being better and below being worse, used to measure the quality of the teams' offense, defense, and opponents. There is also a bye week for each team where they don't play, and the data uses the outdated sixteen-game season with eight played at home and the other eight played away. Lastly, changes in team names and locations are important to consider.

## Main Objective

The main objective of this project is to predict what the attendance per game would have been in the 2020 season if there wasn't a COVID-19 restriction.

## Packages Used In This Analysis





```{r}
#| label: load packages
#| message: false
#| warning: false

library(readr)
library(stringr)
library(tidyr)
library(dplyr)
library(kknn)
library(probably)
library(readxl)
library(janitor)
library(workflows)
library(workflowsets)
library(recipes)
library(rsample)
library(parsnip)
library(yardstick)
library(tune)
library(ggplot2)
library(tidymodels)
library(naniar)
```






| Package | Use |
|-------------------------------|----------------------------------------|
| [here](https://github.com/jennybc/here_here) | to easily load and save data |
| [readr](https://readr.tidyverse.org/) | to import the CSV file data |
| [dplyr](https://dplyr.tidyverse.org/) | to massage and summarize data |
| [rsample](https://rsample.tidymodels.org/) | to split data into training and test sets |
| [ggplot2](https://ggplot2.tidyverse.org/) | to create nice-looking and informative graphs |

FINISH

## Data Description

I am using data on attendance, scores, and other metrics for football teams' games from 2000 to 2019. It is from a Tidy Tuesday from 02/04/2020, which is a community which posts weekly projects. The data is collected from Pro Football Reference which I am also using, and it was most likely collected through nfl.com as there is a game book which states the attendance as the data matches it. It also states the stadiums which would be useful to scrape and the dates and times are also most likely collected from their. The game book states it is paid attendance which is probably collected based on how many tickets are used to enter the stadium.

Tidy Tuesday https://github.com/rfordatascience/tidytuesday/tree/main/data/2020/2020-02-04

Pro Football Reference https://www.pro-football-reference.com/

NFL Website https://www.nfl.com/





```{r}
#| label: import data
#| warning: false
attendance <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/attendance.csv')
standings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/standings.csv')
games <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/games.csv')

stadiums <- clean_names(read_excel(here::here("Final_Project_Data/Stadiums.xls")))

Attendance_2020 <- clean_names(read_excel(here::here("Final_Project_Data/2020Attendance.xls")))
```





### Data Limitations

There are many limitations, such as there not being recorded stadiums, stadium capacity, and the size of the city. There may also be bias in the way that attendance is recorded to make the league seem to have a better performance or for headlines. The methodology that follows also may not be applicable to other sports as the number of games may be vital to whether people attend a game, whether due to fatigue from too many games or better opportunities; however, due to similarities, college football may be applicable. In addition, preseason and playoff data aren't included; however, the methodology that follows may be applicable to them.

## Data Wrangling





```{r}
Attendance_2020 <- Attendance_2020 %>%
  mutate(across(starts_with("week_"), as.numeric)) %>%
  pivot_longer(
    cols = starts_with("week_"),
    names_prefix = "week_",
    names_to = "week",
    values_to = "weekly_attendance"
  )
attendance$newteam <- str_c(attendance$team, attendance$team_name, sep = " ", collapse = NULL)
standings$newteam <- str_c(standings$team, standings$team_name, sep = " ", collapse = NULL)
games$week <- as.numeric(games$week)
games <- games %>%
  drop_na(week)
data <- games %>%
  left_join(attendance, by = c("home_team" = "newteam", "year", "week"))
data <- data %>%
  left_join(standings, by = c("home_team" = "newteam", "year", "team", "team_name"))
stadiums <- stadiums %>%
  separate_rows(primary_team_s, sep = ",")
stadiums <- stadiums %>%
  drop_na(primary_team_s)
stadiums <- stadiums %>%
  rowwise() %>%
  mutate(year = list(from:to)) %>%
  unnest(year) %>%
  select(-from, -to)
stadiums <- stadiums %>%
  filter(year >= 2000)
stadiums <- stadiums %>%
  filter(year <= 2020)
stadiums <- stadiums %>%
  distinct(year, primary_team_s, .keep_all = TRUE)
data <- data %>%
  left_join(stadiums, by = c("home_team" = "primary_team_s", "year"))
```

```{r}
#| label: training and testing set
data_train <- data %>%
  filter(year != 2019)
data_test <- data %>%
  filter(year == 2019)
```





## Exploratory Data Analysis





```{r}
attendance %>%
  miss_var_summary()
count(attendance)/638
```





This corresponds one-to-one to the fact that each team is given one week of the seventeen-week season as a bye week.





```{r}
data_train %>%
summarize(
number = n(),
weekly_attendance_mean = mean(weekly_attendance, na.rm = TRUE),
weekly_attendance_sd = sd(weekly_attendance, na.rm = TRUE),
weekly_attendance_min = min(weekly_attendance, na.rm = TRUE),
weekly_attendance_q1 = quantile(weekly_attendance, 0.25, na.rm = TRUE),
weekly_attendance_median = median(weekly_attendance, na.rm = TRUE),
weekly_attendance_q3 = quantile(weekly_attendance, 0.75, na.rm = TRUE),
weekly_attendance_max = max(weekly_attendance, na.rm = TRUE)
)

ggplot(data = data_train,
       mapping = aes(x = weekly_attendance)
) +
  geom_histogram(center = 57500,
                 binwidth = 5000)

ggplot(data = data_train,
mapping = aes(y = weekly_attendance)
) +
geom_boxplot()
```





Through the table, we can get the total number of values, mean, standard deviation, minimum, median, maximum, and the value at the $25\%$ and $75%$ of attendance in training data. Through the exact values, we notice that attendance is centered between 63,000 and 73,000 people. In addition, all the values are plausible, as there are no recorded negative or exceedingly high values. The histogram shows no large breaks between different recorded attendances, but as the values get more extreme, there are fewer recorded games with such attendance. The boxplot shows a large number of outliers.





```{r}
data_train %>%
 group_by(home_team) %>%
  count()
data_train %>%
  group_by(home_team) %>%
  summarize(
    number = n(),
    weekly_attendance_mean = mean(weekly_attendance, na.rm = TRUE),
    weekly_attendance_sd = sd(weekly_attendance, na.rm = TRUE),
    weekly_attendance_min = min(weekly_attendance, na.rm = TRUE),
    weekly_attendance_q1 = quantile(weekly_attendance, 0.25, na.rm = TRUE),
    weekly_attendance_median = median(weekly_attendance, na.rm = TRUE),
    weekly_attendance_q3 = quantile(weekly_attendance, 0.75, na.rm = TRUE),
    weekly_attendance_max = max(weekly_attendance, na.rm = TRUE)
  )
ggplot(data = data_train, 
       mapping = aes(
         x = home_team,
         y = weekly_attendance
         )
       ) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```





The table above displays the number of games recorded for each home_team as we want to see how many teams are recorded in our data and the names, as there have been teams in the NFL that have changed names. In addition, we can see that there are 152 games recorded for each team, except the Chargers, Rams, and Texans. However, the Chargers and Rams have 152 when adding their other name, leaving only the Texans with 16 home games missing. This makes sense as the Texans joined in the 2002 season.

Through our next table, we can get the total number of values, mean, standard deviation, minimum, median, maximum, and the value at the $25\%$ and $75%$ of attendance broken into teams in our training data. The table provides exact values, so we can see the extreme values from the following box plot. In the box plot, we can see different teams of varying centers and distributions. In addition, we can see that the Los Angeles Chargers and Arizona Cardinals both have a single extremely large attendance record, which is 84301 and 103467 people, respectively. It can also be seen that the Dallas Cowboys almost always have extremely high attendance compared to other teams. Therefore, due to the differences between teams, home_team is likely a significant predictor for weekly_attendance.






```{r}
data_train2 <- data_train
data_train2$year <- as.factor(data_train$year)
data_train2$week <- as.factor(data_train$week)
ggplot(data = data_train2,
mapping = aes(
x = year,
y = weekly_attendance
)
) +
geom_boxplot()
ggplot(data = data_train,
mapping = aes(
x = day,
y = weekly_attendance
)
) +
geom_boxplot()
ggplot(data = data_train2,
mapping = aes(
x = week,
y = weekly_attendance
)
) +
geom_boxplot()
ggplot(data = data_train,
mapping = aes(
x = time,
y = weekly_attendance
)
) +
geom_point()
```





The above plots show that attendance doesn't change significantly based on the day, week, or year the game is played.

## More Data Wrangling





```{r}
data_train <- data_train %>%
  mutate(last_word = str_extract(home_team, "\\w+$")) %>%
  mutate(home_team = ifelse(duplicated(last_word) | duplicated(last_word, fromLast = TRUE),
                            last_word, 
                            home_team)) %>%
  select(-last_word)
data_train <- data_train %>%
  mutate(last_word = str_extract(away_team, "\\w+$")) %>%
  mutate(away_team = ifelse(duplicated(last_word) | duplicated(last_word, fromLast = TRUE),
                            last_word, 
                            away_team)) %>%
  select(-last_word)
data_test <- data_test %>%
  mutate(last_word = str_extract(home_team, "\\w+$")) %>%
  mutate(home_team = ifelse(duplicated(last_word) | duplicated(last_word, fromLast = TRUE),
                            last_word, 
                            home_team)) %>%
  select(-last_word)
data_test <- data_test %>%
  mutate(last_word = str_extract(away_team, "\\w+$")) %>%
  mutate(away_team = ifelse(duplicated(last_word) | duplicated(last_word, fromLast = TRUE),
                            last_word, 
                            away_team)) %>%
  select(-last_word)
```





## Modeling





```{r}
lm1 <- lm(weekly_attendance ~ home_team + away_team + week + year + day + time, data = data_train)
summary(lm1)
plot(lm1)

linreg_model <- linear_reg(mode = "regression", engine = "lm")
knn_model <- nearest_neighbor(mode = "regression",
                              engine = "kknn",
                              neighbors = 8, dist_power = 2)

linear_recipe <- recipe(
  weekly_attendance ~ home_team + away_team + week + year, # response ~ predictors
  data = data_train
)

quadratic_recipe <- recipe(
  weekly_attendance ~ home_team + away_team + week + year, # response ~ predictors
  data = data_train
) |>
  step_poly(week, degree = 2)

interaction_recipe <- recipe(
  weekly_attendance ~ home_team + away_team + week + year, # response ~ predictors
  data = data_train
) |>
  step_interact(terms = ~week:year) # add HR:BB interaction term

knn_recipe <- recipe(
  weekly_attendance ~ home_team + away_team + week + year,
  data = data_train
) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors())

all_models <- workflow_set(
  preproc = list(linear = linear_recipe, quadratic = quadratic_recipe,
                 interaction = interaction_recipe, knn = knn_recipe),
  models = list(lr = linreg_model, lr = linreg_model,
                lr = linreg_model, knn = knn_model),
  cross = FALSE # don't mix knn recipes with linear models or vice-versa
)
all_models

set.seed(1112)
data_cv <- vfold_cv(data_train, v = 10)

all_models <- all_models |>
  workflow_map("fit_resamples",
               resamples = data_cv,
               metrics = metric_set(rmse, mae),
               verbose = TRUE) # lets you know where you are in the fitting process

knn_model2 <- nearest_neighbor(mode = "regression", 
                               engine = "kknn",
                               neighbors = tune(), 
                               dist_power = 2)

knn.grid <- expand.grid(neighbors = seq(1,20, by = 1))

all_models2 <- workflow_set(
  preproc = list(linear = linear_recipe, 
                 quadratic = quadratic_recipe,
                 interaction = interaction_recipe, 
                 knn = knn_recipe),
  models = list(lr = linreg_model, 
                lr = linreg_model,
                lr = linreg_model,
                knn2 = knn_model2),
  cross = FALSE 
)

all_models2 <- all_models2 |>
  # add the grid for JUST the knn model
  option_add(grid = knn.grid, id = "knn_knn2") |>
  workflow_map("tune_grid",
               resamples = data_cv,
               metrics = metric_set(rmse), # can add more
               verbose = TRUE)

autoplot(all_models2)

autoplot(all_models2, id = "knn_knn2")

rank_results(all_models2) |>
  dplyr::select(wflow_id, .config, .metric, mean, std_err, rank) |>
  arrange(.metric, rank)

best_k <- all_models2 |> 
  extract_workflow_set_result(id = "knn_knn2") |> 
  select_best(metric = "rmse")
  
my_best_knn <- all_models2 |>
  extract_workflow("knn_knn2") |>
  finalize_workflow(parameters = best_k)

my_best_knn
```

```{r}
best_model_refit <- my_best_knn |>
  fit_resamples(
    resamples = data_cv,
    # save the cross-validated predictions
    control = control_resamples(save_pred = TRUE)
)

predictions_best_model <- best_model_refit |>
  collect_predictions()

cal_plot_regression(
  predictions_best_model,
  truth = weekly_attendance,
  estimate = .pred
)

best_model_refit |>
  cal_validate_linear(
    save_pred = TRUE,
    smooth = TRUE) |> # nonlinear smoothing, use smooth = FALSE for linear transformation
  collect_predictions() |>
  cal_plot_regression(
    truth = weekly_attendance,
    estimate = .pred
  )

calibrate_knn <- predictions_best_model |>
  # instructions for post-processing
  cal_estimate_linear(
    truth = weekly_attendance,
    smooth = TRUE # nonlinear smoothing
  )

knn_fit <- my_best_knn |> fit(
  data = data_train
)

knn_test_pred2 <- knn_fit |>
  augment(new_data = data_test) |>
  # apply the post-processing
  cal_apply(calibrate_knn)

knn_test_pred2
```

```{r}
treeR_model <- decision_tree(mode = "regression", engine = "rpart",
                          cost_complexity = tune())

treeR_recipe <- recipe(
  weekly_attendance ~ home_team + away_team + week + year, # response ~ predictors
  data = data_train
)

treeR_wflow <- workflow() |>
  add_model(treeR_model) |>
  add_recipe(treeR_recipe)

data_kfold <- vfold_cv(data_train, v = 5, repeats = 3) 

treeR_tune1 <- tune_grid(treeR_model, 
                      treeR_recipe, 
                      resamples = data_kfold, 
                      metrics = metric_set(rmse), # ignore r-squared, we get warning messages
                      grid = grid_regular(cost_complexity(range = c(-3, 0)), levels = 10))

treeR_tune1 |>
  collect_metrics() |> # no need to filter for RMSE because it's the only one 
  ggplot(mapping = aes(x = cost_complexity, y = mean)) + 
  geom_point() + 
  geom_line() +
  scale_x_log10()

treeR_best <- select_by_one_std_err(
  treeR_tune1,
  metric = "rmse",
  desc(cost_complexity)
)
treeR_best

treeR_wflow_final <- finalize_workflow(treeR_wflow, parameters = treeR_best) 

treeR_pred_check <- treeR_wflow_final |>
  fit_resamples(
    resamples = data_kfold,
    # save the cross-validated predictions
    control = control_resamples(save_pred = TRUE)
) |> 
  collect_predictions()

ggplot(treeR_pred_check, aes(x = weekly_attendance, y = .pred)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "blue")
```





## Insights

### Limitations and Future Work

### Reflection (Optional Subsection)

