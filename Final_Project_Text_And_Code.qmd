---
title: "NFL Attendance"
format:
  html:
      code-block-background: FALSE
---

## Motivation and Context

```{r}
#| label: do this first
#| echo: false
#| message: false

here::i_am("Final_Project_Text_And_Code.qmd")
```

This section describes what you are investigating in your project and why you are investigating it. You should provide enough contextual background and information that someone with a limited background can understand the broad outlines of the topic being investigated.

I am investigating attendance at NFL games because it is interesting to delve into the many factors that play into why a person would go to a stadium rather than simply watch from home. The time of day, date, loyalty to a team, cost, and rivalries may all play a role. There are also other monetary reasons one should consider investigating future attendance. For instance, given a predicted increase, which isn't possible due to stadium limitations, renovating stadiums for additional seats may become a priority. In addition, there are dynamic reasons, such as ticket prices and the number of staff, which can change depending on predicted attendance.

The background to understand NFL game attendance is the locations of stadiums and the popularity of teams. While how the game is played is interesting, it isn't vital to the analysis as long as we know that higher scores are better. There is, however, a simple rating system where 0 is an average team, with above zero being better and below being worse, used to measure the quality of the teams' offense, defense, and opponents. There is also a bye week for each team where they don't play, and the data uses the outdated sixteen-game season with eight played at home and the other eight played away. Lastly, changes in team names and locations are important to consider.

## Main Objective

The main objective of this project is to predict what the attendance per game would have been in the 2020 season if there wasn't a COVID-19 restriction.

## Packages Used In This Analysis

```{r}
#| label: load packages
#| message: false
#| warning: false
library(readr)
library(stringr)
library(dplyr)
library(ggplot2)
library(naniar)
library(workflows)
library(workflowsets)
library(tune)
library(recipes)
library(kknn)
library(rsample)
library(parsnip)
library(tidyr)
library(tidymodels)
library(probably)
library(vip)
library(xgboost)
```


| Package | Use |
|-------------------------------|----------------------------------------|
| [readr] | read in csv |
| [stringr] | Separate strings into new rows by commas |
| [dplyr] | In order to join data |
| [ggplot2] | To plot data |
| [naniar] | To plot and use missing data |
| [workflows] | To make tidy models |
| [workflowsets] | Also to make tidy models |
| [tune] | To cross validate |
| [recipes] | To build recipes for tidy model |
| [kknn] | To build knn models |
| [rsample] | For building cross validation data |
| [parsnip] | For building knn too |
| [tidyr] | To drop na values and adjust data |
| [tidymodels] | To make grids and other modeling |
| [probably] | To calibrate knn model |
| [vip] | For variable importance plot |
| [xgboost] | For boosted trees |
 ...

## Data Description

I am using data on attendance, scores, and other metrics for football teams' games from 2000 to 2019. It is from a Tidy Tuesday from 02/04/2020, which is a community that posts weekly projects. The data is collected from Pro Football Reference, which I am also using, and it was most likely collected through nfl.com as there is a gamebook that states the attendance as the data matches it. It also states the stadiums that would be useful to scrape, and the dates and times are also most likely collected from them. The game book states that paid attendance is probably collected based on how many tickets are used to enter the stadium. I have looked at and downloaded some stadiums and data for 2020; however, the data wrangling required exceeds the time remaining to complete the project.

Tidy Tuesday https://github.com/rfordatascience/tidytuesday/tree/main/data/2020/2020-02-04

Pro Football Reference https://www.pro-football-reference.com/

NFL Website https://www.nfl.com/

```{r}
#| label: import data
#| warning: false
attendance <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/attendance.csv')
standings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/standings.csv')
games <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/games.csv')
```

### Data Limitations

There are many limitations, such as there not being recorded stadiums, stadium capacity, and the size of the city. There may also be bias in the way that attendance is recorded to make the league seem to have a better performance or for headlines. The methodology that follows also may not be applicable to other sports as the number of games may be vital to whether people attend a game, whether due to fatigue from too many games or better opportunities; however, due to similarities, college football may be applicable. In addition, preseason and playoff data aren't included; however, the methodology that follows may be applicable to them.

## Data Wrangling

I am combining my datasets into one for prediction and making weeks into a categorical variable since they aren't increasing linearly and it accounts for how one week may be higher than another week due to holidays or etc.

```{r}
attendance$newteam <- str_c(attendance$team, attendance$team_name, sep = " ", collapse = NULL)
standings$newteam <- str_c(standings$team, standings$team_name, sep = " ", collapse = NULL)
games$week <- as.numeric(games$week)
games <- games %>%
  drop_na(week)
data <- games %>%
  left_join(attendance, by = c("home_team" = "newteam", "year", "week"))
data <- data %>%
  left_join(standings, by = c("home_team" = "newteam", "year", "team", "team_name"))
```

I am filtering the data to only include the last 5 years since the NFL changes at a fast pace. In addition, I tested including more data and it made the predictions worse.

```{r}
#| label: training and testing set
data_train <- data %>%
  filter(year != 2019 & year > 2013)
data_test <- data %>%
  filter(year == 2019)
data_train$week <- as.factor(data_train$week)
data_test$week <- as.factor(data_test$week)
```

## Exploratory Data Analysis

```{r}
attendance %>%
  miss_var_summary()
count(attendance)/638
```

This corresponds one-to-one to the fact that each team is given one week of the seventeen-week season as a bye week.

```{r}
data_train %>%
summarize(
number = n(),
weekly_attendance_mean = mean(weekly_attendance, na.rm = TRUE),
weekly_attendance_sd = sd(weekly_attendance, na.rm = TRUE),
weekly_attendance_min = min(weekly_attendance, na.rm = TRUE),
weekly_attendance_q1 = quantile(weekly_attendance, 0.25, na.rm = TRUE),
weekly_attendance_median = median(weekly_attendance, na.rm = TRUE),
weekly_attendance_q3 = quantile(weekly_attendance, 0.75, na.rm = TRUE),
weekly_attendance_max = max(weekly_attendance, na.rm = TRUE)
)

ggplot(data = data_train,
       mapping = aes(x = weekly_attendance)
) +
  geom_histogram(center = 57500,
                 binwidth = 5000)

ggplot(data = data_train,
mapping = aes(y = weekly_attendance)
) +
geom_boxplot()
```

Through the table, we can get the total number of values, mean, standard deviation, minimum, median, maximum, and the value at the $25\%$ and $75%$ of attendance in training data. Through the exact values, we notice that attendance is centered between 63,000 and 73,000 people. In addition, all the values are plausible, as there are no recorded negative or exceedingly high values. The histogram shows no large breaks between different recorded attendances, but as the values get more extreme, there are fewer recorded games with such attendance. The boxplot shows a large number of outliers.

```{r}
data_train %>%
 group_by(home_team) %>%
  count()
data_train %>%
  group_by(home_team) %>%
  summarize(
    number = n(),
    weekly_attendance_mean = mean(weekly_attendance, na.rm = TRUE),
    weekly_attendance_sd = sd(weekly_attendance, na.rm = TRUE),
    weekly_attendance_min = min(weekly_attendance, na.rm = TRUE),
    weekly_attendance_q1 = quantile(weekly_attendance, 0.25, na.rm = TRUE),
    weekly_attendance_median = median(weekly_attendance, na.rm = TRUE),
    weekly_attendance_q3 = quantile(weekly_attendance, 0.75, na.rm = TRUE),
    weekly_attendance_max = max(weekly_attendance, na.rm = TRUE)
  )
ggplot(data = data_train, 
       mapping = aes(
         x = home_team,
         y = weekly_attendance
         )
       ) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(data = data_train, 
       mapping = aes(
         x = away_team,
         y = weekly_attendance
         )
       ) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

The table above displays the number of games recorded for each home_team as we want to see how many teams are recorded in our data and the names, as there have been teams in the NFL that have changed names. In addition, we can see that there are 40 games recorded for each team, except the Chargers, Rams, and Texans. However, the Chargers and Rams have theirs split into different teams in 2017 and 2016, respectively.

Through our next table, we can get the total number of values, mean, standard deviation, minimum, median, maximum, and the value at the $25\%$ and $75%$ of attendance broken into teams in our training data. The table provides exact values, so we can see the extreme values from the following box plot. In the box plot, we can see different teams of varying centers and distributions. In addition, we can see that the Los Angeles Chargers has a single extremely large attendance record, which is 84301 people. It can also be seen that the Dallas Cowboys almost always have extremely high attendance compared to other teams. Therefore, due to the differences between teams, home_team is likely a significant predictor for weekly_attendance. The same can be said for away team as well but it is significantly less severe.

```{r}
ggplot(data = data_train,
mapping = aes(
x = year,
y = weekly_attendance
)
) +
geom_point()
ggplot(data = data_train,
mapping = aes(
x = day,
y = weekly_attendance
)
) +
geom_boxplot()
ggplot(data = data_train,
mapping = aes(
x = week,
y = weekly_attendance
)
) +
geom_boxplot()
ggplot(data = data_train,
mapping = aes(
x = simple_rating,
y = weekly_attendance
)
) +
geom_point()
ggplot(data = data_train,
mapping = aes(
x = time,
y = weekly_attendance
)
) +
geom_point()
```
The above plots show that attendance doesn't change significantly based on the simple rating, day, week, or year the game is played; however, it is impacted by time, but since there are different time zones, it doesn’t make much sense to use.

## Modeling

I am performing a k-nearest neighbors as assumptions for linear regression has failed the condition of equal variance. K-nearest-neighbors is non-parametric so it has looser conditions and works by using the training set to identify the k points closest to the point we want to predict. Then an average is taken in order to make our prediction.

I am using the home_team and away_team in my prediction as they can catch information not in variables in my dataset such stadium and team strength. I am also using week and year as I feel they can be used to show the changes in time, but year is numerical as it isn't in the testing set otherwise.

```{r}
lm1 <- lm(weekly_attendance ~ home_team + away_team + week + year, data = data_train)
summary(lm1)
plot(lm1)
```

```{r}
knn_recipe <- recipe(
  weekly_attendance ~ home_team + away_team + week + year,
  data = data_train
) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors(), one_hot = TRUE)

knn_model <- nearest_neighbor(mode = "regression", 
                               engine = "kknn",
                               neighbors = tune(), 
                               dist_power = 2)

knn_wflow <- workflow() |>
  add_model(knn_model)

data_cv <- vfold_cv(data_train, v = 10)

knn.grid <- expand.grid(neighbors = seq(1,20, by = 1))

knn_wflow <- knn_wflow |>
  add_recipe(knn_recipe)

knn_tune <- tune_grid(knn_model,
knn_recipe,
resamples = data_cv,
grid = knn.grid)

autoplot(knn_tune)

knn_best <- knn_tune |>
  select_best(metric = "rmse")
knn_best

my_best_knn <- knn_wflow |>
  finalize_workflow(parameters = knn_best)
my_best_knn
```

I choose my best model based on the lowest root mean squared error, which we want to minimize as it is calculated as $\sqrt{\frac{1}{n}\sum_{i=1}^n(y_i-\hat{f}(x_i))^2}$. This is the square root of one over the total number of observations times the sum over the observations of the actual values minus the predicted values squared. Therefore, when the root mean squared error is closer to 0, the actual values are closer to the predicted values.

```{r}
xgboostR_model <- boost_tree(mode = "regression", engine = "xgboost",
                            trees = tune(), tree_depth = tune(),
                            learn_rate = tune())

xgboostR_recipe <- recipe(
  weekly_attendance ~ home_team + away_team + week + year,, # response ~ predictors
  data = data_train
) |>
  step_dummy(all_nominal_predictors())

xgboostR_wflow <- workflow() |>
  add_model(xgboostR_model) |>
  add_recipe(xgboostR_recipe)

set.seed(1486)
xgboostR_tune <- tune_grid(xgboostR_model, 
                      xgboostR_recipe, 
                      resamples = data_cv,
                      metrics = metric_set(rmse),
                      grid = grid_space_filling(
                        trees(), 
                        tree_depth(), 
                        learn_rate(), 
                        size = 3)) # search over 20 possible combinations of the three parameters - keep this small if you don't want it running forever

xgboostR_tune |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  arrange(mean)

xgboostR_best <- select_by_one_std_err(xgboostR_tune, 
                             metric = "rmse", 
                             tree_depth, trees, desc(learn_rate))
xgboostR_wflow_final <- finalize_workflow(xgboostR_wflow, 
                                          parameters = xgboostR_best) 

xgboostR_fit <- fit(xgboostR_wflow_final, data = data_train)
xgboostR_predict <- augment(xgboostR_fit, new_data = data_test)
xgboostR_predict |> 
  dplyr::slice(1:10) # must use dplyr::slice because there is also a slice function in xgboost
rmse(xgboostR_predict, truth = weekly_attendance, estimate = .pred)
```

I am running a boosted tree here which works by trees being grown sequentially from previous trees formed thorugh a modified version of the dataset. They work by splitting trees into sections based on predictors until enough splits are made in order for the predictions to be accurate but splits are controlled so it doesn't split until groups are one.

I am cross validating the same way as for knn but with the highest rmse within one standard deviation of the lowest.

## Insights

```{r}
best_model_refit <- my_best_knn |>
  fit_resamples(
    resamples = data_cv,
    # save the cross-validated predictions
    control = control_resamples(save_pred = TRUE)
)

predictions_best_model <- best_model_refit |>
  collect_predictions()

cal_plot_regression(
  predictions_best_model,
  truth = weekly_attendance,
  estimate = .pred
)

best_model_refit |>
  cal_validate_linear(
    save_pred = TRUE,
    smooth = TRUE) |> # nonlinear smoothing, use smooth = FALSE for linear transformation
  collect_predictions() |>
  cal_plot_regression(
    truth = weekly_attendance,
    estimate = .pred
  )

calibrate_knn <- predictions_best_model |>
  # instructions for post-processing
  cal_estimate_linear(
    truth = weekly_attendance,
    smooth = TRUE # nonlinear smoothing
  )

knn_fit <- my_best_knn |> fit(
  data = data_train
)

knn_test_pred2 <- knn_fit |>
  augment(new_data = data_test) |>
  # apply the post-processing
  cal_apply(calibrate_knn)


clean <- knn_test_pred2
clean$difference <- (clean$.pred-clean$weekly_attendance)
clean %>%
  sort_by(clean$difference)
```

Our test set of 2019 data shows that our model isn't that great at predicting attendance, except for attendance between about 65,000 and 75,000. In addition, predictions get further from our observed when further from the middle value at about 70,000.

```{r}
xgboostR_fit |> extract_fit_engine() |>
      vip(scale = TRUE)

plot(xgboostR_predict$.pred, xgboostR_predict$weekly_attendance) +
  abline(0,1)
```

I also ran an importance plot on a boosted tree model. The highest importance is the LA Chargers most likely because there aren't that many games recorded for them and they are getting significantly less attendance than the rest of the NFL. It is followed by the Dallas Cowboys probably because they have a higher attendance than the mean. The years show that it is the next most used in splitting the data.

The plot also shows that our predictions are closer to our actual values than the knn model.

### Limitations and Future Work

The knn model is poorly predicting games with attendance that don't fall between 60,000 and 80,000 attendants. This is likely due to a majority of values being there for use in k-nearest neighbors, while further values have less similar options. The data collection and analysis would be significantly improved if stadium data were readily available in a precleaned way. The boosted trees also performs better but it may be due to overfitting and shows the importance of stadiums as the teams were used significantly. In addition, rivalries between teams could be another indicator of attendance. Since I am using a non-parametric approach, the assumptions are satisfied. There are some ethical concerns, such as if there is a great prediction, then teams might hire fewer workers during low attendance games, and ticket prices might be raised on high attendance games.

### Reflection

This project has made me appreciate the difficulty of working with online data and how many of the methods we learned in class have to examined and thought about before being applied to projects.

How did doing this project increase your understanding of statistical learning and/or the real-world domain you investigated? (It's perfectly okay to say you learned nothing, in which case you should explain why.) 
This project made me understand the complexity of working with datasets collected by other people and how much bad data there is to work with. In the presentations, I listened to a common theme, synthetic data from Kaggle, and the main insight was a lack of connection. The project also granted me a better understanding of game attendance and how much data would be nice to have in order to predict future attendance. There was also domain-specific knowledge I got a better understanding of, such as the fact that there is a bye week for each NFL team in the regular season. In addition, I understand how many limitations a project can have, with stadium data being a recurring theme of what I would need in order to make a deeper analysis. The project also provided me with the method to build and adjust a website. I plan to continue using the technique of building a website for my resume and further academic projects. 
How have you grown as a mathematician, statistician, and/or data scientist through taking Math 437 this semester? How do you hope to continue growing in the near future as a mathematician, statistician, and/or data scientist, and how (if at all) has Math 437 influenced those ideas? 
I have grown significantly through taking this class. I have learned more about statistical methods for modeling regression and classification. I hope to continue growing in the near future by pursuing a PhD at Florida State University. In addition, I plan to continue doing research on this subject. Math 437 has influenced my approach to statistics by making me learn to apply more methods and the importance of learning the methodology and requirements in order to use certain methods.
What were you most proud of accomplishing in this class, and why? (This can be a "little win" like "solving Problem X on Homework Y on my own" or "getting Lab Z to render correctly on the first try.")
My proudest accomplishment in this class is my grade on the conceptual exam because I put multiple hours into creating an all-encompassing study guide in order to make it as simple as possible. I went through the book and example code to relearn the material in preparation, and I felt that my grade on it was a reflection of my effort in the class. I would like to hope that my overall grade in the class will end up being my greatest accomplishment.