---
title: "NFL Attendance"
---

## Motivation and Context

```{r}
#| label: do this first
#| echo: false
#| message: false

here::i_am("Final_Project_Text_And_Code.qmd")
```

This section describes what you are investigating in your project and why you are investigating it. You should provide enough contextual background and information that someone with a limited background can understand the broad outlines of the topic being investigated.

I am investigating attendance at NFL games because it is interesting to delve into the many factors that play into why a person would go to a stadium rather than simply watch from home. The time of day, date, loyalty to a team, cost, and rivalries may all play a role. There are also other monetary reasons one should consider investigating future attendance. For instance, given a predicted increase, which isn't possible due to stadium limitations, renovating stadiums for additional seats may become a priority. In addition, there are dynamic reasons, such as ticket prices and the number of staff, which can change depending on predicted attendance.

The background to understand NFL game attendance is the locations of stadiums and the popularity of teams. While how the game is played is interesting, it isn't vital to the analysis as long as we know that higher scores are better. There is, however, a simple rating system where 0 is an average team, with above zero being better and below being worse, used to measure the quality of the teams' offense, defense, and opponents. There is also a bye week for each team where they don't play, and the data uses the outdated sixteen-game season with eight played at home and the other eight played away. Lastly, changes in team names and locations are important to consider.

## Main Objective

The main objective of this project is to predict what the attendance per game would have been in the 2020 season if there wasn't a COVID-19 restriction.

## Packages Used In This Analysis

```{r}
#| label: load packages
#| message: false
#| warning: false

library(readr)
library(stringr)
library(tidyr)
library(dplyr)
library(kknn)
library(probably)
library(readxl)
library(janitor)
library(workflows)
library(workflowsets)
library(recipes)
library(rsample)
library(parsnip)
library(yardstick)
library(tune)
library(ggplot2)
library(tidymodels)
library(naniar)
```


| Package | Use |
|-------------------------------|----------------------------------------|
| [readr] | read in csv |
 ...
 
 FINISH

## Data Description

I am using data on attendance, scores, and other metrics for football teams' games from 2000 to 2019. It is from a Tidy Tuesday from 02/04/2020, which is a community which posts weekly projects. The data is collected from Pro Football Reference which I am also using, and it was most likely collected through nfl.com as there is a game book which states the attendance as the data matches it. It also states the stadiums which would be useful to scrape and the dates and times are also most likely collected from their. The game book states it is paid attendance which is probably collected based on how many tickets are used to enter the stadium.

Tidy Tuesday https://github.com/rfordatascience/tidytuesday/tree/main/data/2020/2020-02-04

Pro Football Reference https://www.pro-football-reference.com/

NFL Website https://www.nfl.com/

```{r}
#| label: import data
#| warning: false
attendance <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/attendance.csv')
standings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/standings.csv')
games <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/games.csv')

stadiums <- clean_names(read_excel(here::here("Final_Project_Data/Stadiums.xls")))

Attendance_2020 <- clean_names(read_excel(here::here("Final_Project_Data/2020Attendance.xls")))
```

### Data Limitations

There are many limitations, such as there not being recorded stadiums, stadium capacity, and the size of the city. There may also be bias in the way that attendance is recorded to make the league seem to have a better performance or for headlines. The methodology that follows also may not be applicable to other sports as the number of games may be vital to whether people attend a game, whether due to fatigue from too many games or better opportunities; however, due to similarities, college football may be applicable. In addition, preseason and playoff data aren't included; however, the methodology that follows may be applicable to them.

## Data Wrangling

```{r}
Attendance_2020 <- Attendance_2020 %>%
  mutate(across(starts_with("week_"), as.numeric)) %>%
  pivot_longer(
    cols = starts_with("week_"),
    names_prefix = "week_",
    names_to = "week",
    values_to = "weekly_attendance"
  )
Attendance_2020$year <- 2020
Attendance_2020$home_team <- Attendance_2020$tm
Attendance_2020$week <- as.double(Attendance_2020$week)
attendance$newteam <- str_c(attendance$team, attendance$team_name, sep = " ", collapse = NULL)
standings$newteam <- str_c(standings$team, standings$team_name, sep = " ", collapse = NULL)
games$week <- as.numeric(games$week)
games <- games %>%
  drop_na(week)
data <- games %>%
  left_join(attendance, by = c("home_team" = "newteam", "year", "week"))
data <- data %>%
  left_join(standings, by = c("home_team" = "newteam", "year", "team", "team_name"))
stadiums <- stadiums %>%
  separate_rows(primary_team_s, sep = ",")
stadiums <- stadiums %>%
  drop_na(primary_team_s)
stadiums <- stadiums %>%
  rowwise() %>%
  mutate(year = list(from:to)) %>%
  unnest(year) %>%
  select(-from, -to)
stadiums <- stadiums %>%
  filter(year >= 2000)
stadiums <- stadiums %>%
  filter(year <= 2020)
stadiums <- stadiums %>%
  distinct(year, primary_team_s, .keep_all = TRUE)
data <- data %>%
  left_join(stadiums, by = c("home_team" = "primary_team_s", "year"))
```

```{r}
#| label: training and testing set
data_train <- data %>%
  filter(year != 2019)
data_test <- data %>%
  filter(year == 2019)
```

## Exploratory Data Analysis

```{r}
attendance %>%
  miss_var_summary()
count(attendance)/638
```

This corresponds one-to-one to the fact that each team is given one week of the seventeen-week season as a bye week.

```{r}
data_train %>%
summarize(
number = n(),
weekly_attendance_mean = mean(weekly_attendance, na.rm = TRUE),
weekly_attendance_sd = sd(weekly_attendance, na.rm = TRUE),
weekly_attendance_min = min(weekly_attendance, na.rm = TRUE),
weekly_attendance_q1 = quantile(weekly_attendance, 0.25, na.rm = TRUE),
weekly_attendance_median = median(weekly_attendance, na.rm = TRUE),
weekly_attendance_q3 = quantile(weekly_attendance, 0.75, na.rm = TRUE),
weekly_attendance_max = max(weekly_attendance, na.rm = TRUE)
)

ggplot(data = data_train,
       mapping = aes(x = weekly_attendance)
) +
  geom_histogram(center = 57500,
                 binwidth = 5000)

ggplot(data = data_train,
mapping = aes(y = weekly_attendance)
) +
geom_boxplot()
```

Through the table, we can get the total number of values, mean, standard deviation, minimum, median, maximum, and the value at the $25\%$ and $75%$ of attendance in training data. Through the exact values, we notice that attendance is centered between 63,000 and 73,000 people. In addition, all the values are plausible, as there are no recorded negative or exceedingly high values. The histogram shows no large breaks between different recorded attendances, but as the values get more extreme, there are fewer recorded games with such attendance. The boxplot shows a large number of outliers.

```{r}
data_train %>%
 group_by(home_team) %>%
  count()
data_train %>%
  group_by(home_team) %>%
  summarize(
    number = n(),
    weekly_attendance_mean = mean(weekly_attendance, na.rm = TRUE),
    weekly_attendance_sd = sd(weekly_attendance, na.rm = TRUE),
    weekly_attendance_min = min(weekly_attendance, na.rm = TRUE),
    weekly_attendance_q1 = quantile(weekly_attendance, 0.25, na.rm = TRUE),
    weekly_attendance_median = median(weekly_attendance, na.rm = TRUE),
    weekly_attendance_q3 = quantile(weekly_attendance, 0.75, na.rm = TRUE),
    weekly_attendance_max = max(weekly_attendance, na.rm = TRUE)
  )
ggplot(data = data_train, 
       mapping = aes(
         x = home_team,
         y = weekly_attendance
         )
       ) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

The table above displays the number of games recorded for each home_team as we want to see how many teams are recorded in our data and the names, as there have been teams in the NFL that have changed names. In addition, we can see that there are 152 games recorded for each team, except the Chargers, Rams, and Texans. However, the Chargers and Rams have 152 when adding their other name, leaving only the Texans with 16 home games missing. This makes sense as the Texans joined in the 2002 season.

Through our next table, we can get the total number of values, mean, standard deviation, minimum, median, maximum, and the value at the $25\%$ and $75%$ of attendance broken into teams in our training data. The table provides exact values, so we can see the extreme values from the following box plot. In the box plot, we can see different teams of varying centers and distributions. In addition, we can see that the Los Angeles Chargers and Arizona Cardinals both have a single extremely large attendance record, which is 84301 and 103467 people, respectively. It can also be seen that the Dallas Cowboys almost always have extremely high attendance compared to other teams. Therefore, due to the differences between teams, home_team is likely a significant predictor for weekly_attendance.


```{r}
data_train2 <- data_train
data_train2$year <- as.factor(data_train$year)
data_train2$week <- as.factor(data_train$week)
ggplot(data = data_train2,
mapping = aes(
x = year,
y = weekly_attendance
)
) +
geom_boxplot()
ggplot(data = data_train,
mapping = aes(
x = day,
y = weekly_attendance
)
) +
geom_boxplot()
ggplot(data = data_train2,
mapping = aes(
x = week,
y = weekly_attendance
)
) +
geom_boxplot()
ggplot(data = data_train,
mapping = aes(
x = simple_rating,
y = weekly_attendance
)
) +
geom_point()
ggplot(data = data_train,
mapping = aes(
x = time,
y = weekly_attendance
)
) +
geom_point()
```
The above plots show that attendance doesn't change significantly based on the simple rating, day, week, or year the game is played; however, it is impacted by time, but since there are different time zones, it doesnâ€™t make much sense to use.

## More Data Wrangling

```{r}
data_train <- data_train %>%
  mutate(last_word = str_extract(home_team, "\\w+$")) %>%
  mutate(home_team = ifelse(duplicated(last_word) | duplicated(last_word, fromLast = TRUE),
                            last_word, 
                            home_team)) %>%
  select(-last_word)
data_train <- data_train %>%
  mutate(last_word = str_extract(away_team, "\\w+$")) %>%
  mutate(away_team = ifelse(duplicated(last_word) | duplicated(last_word, fromLast = TRUE),
                            last_word, 
                            away_team)) %>%
  select(-last_word)
data_test <- data_test %>%
  mutate(last_word = str_extract(home_team, "\\w+$")) %>%
  mutate(home_team = ifelse(duplicated(last_word) | duplicated(last_word, fromLast = TRUE),
                            last_word, 
                            home_team)) %>%
  select(-last_word)
data_test <- data_test %>%
  mutate(last_word = str_extract(away_team, "\\w+$")) %>%
  mutate(away_team = ifelse(duplicated(last_word) | duplicated(last_word, fromLast = TRUE),
                            last_word, 
                            away_team)) %>%
  select(-last_word)
Attendance_2020 <- Attendance_2020 %>%
  mutate(last_word = str_extract(home_team, "\\w+$")) %>%
  mutate(home_team = ifelse(duplicated(last_word) | duplicated(last_word, fromLast = TRUE),
                            last_word, 
                            home_team)) %>%
  select(-last_word)
```

## Modeling

I am performing a k-nearest neighbors as assumptions for linear regression has failed the condition of equal variance. K-nearest-neighbors is non-parametric so it has looser conditions and works by using the training set to identify the k points closest to the point we want to predict. Then an average is taken in order to make our prediction.

```{r}
lm1 <- lm(weekly_attendance ~ home_team + away_team + week + year, data = data_train)
summary(lm1)
plot(lm1)
```

```{r}
knn_recipe <- recipe(
  weekly_attendance ~ home_team + away_team + week + year,
  data = data_train
) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors(), one_hot = TRUE)

knn_model <- nearest_neighbor(mode = "regression", 
                               engine = "kknn",
                               neighbors = tune(), 
                               dist_power = 2)

knn_wflow <- workflow() |>
  add_model(knn_model)

data_cv <- vfold_cv(data_train, v = 10)

knn.grid <- expand.grid(neighbors = seq(1,20, by = 1))

knn_wflow <- knn_wflow |>
  add_recipe(knn_recipe)

knn_tune <- tune_grid(knn_model,
knn_recipe,
resamples = data_cv,
grid = knn.grid)

autoplot(knn_tune)

knn_best <- knn_tune |>
  select_best(metric = "rmse")
knn_best

my_best_knn <- knn_wflow |>
  finalize_workflow(parameters = knn_best)
my_best_knn
```

I choose my best model based on the lowest root mean squared error, which we want to minimize as it is calculated as $\sqrt{\frac{1}{n}\sum_{i=1}^n(y_i-\hat{f}(x_i))^2}$. This is the square root of one over the total number of observations times the sum over the observations of the actual values minus the predicted values squared. Therefore, when the root mean squared error is closer to 0, the actual values are closer to the predicted values.

## Insights

```{r}
best_model_refit <- my_best_knn |>
  fit_resamples(
    resamples = data_cv,
    # save the cross-validated predictions
    control = control_resamples(save_pred = TRUE)
)

predictions_best_model <- best_model_refit |>
  collect_predictions()

cal_plot_regression(
  predictions_best_model,
  truth = weekly_attendance,
  estimate = .pred
)

best_model_refit |>
  cal_validate_linear(
    save_pred = TRUE,
    smooth = TRUE) |> # nonlinear smoothing, use smooth = FALSE for linear transformation
  collect_predictions() |>
  cal_plot_regression(
    truth = weekly_attendance,
    estimate = .pred
  )

calibrate_knn <- predictions_best_model |>
  # instructions for post-processing
  cal_estimate_linear(
    truth = weekly_attendance,
    smooth = TRUE # nonlinear smoothing
  )

knn_fit <- my_best_knn |> fit(
  data = data_train
)

knn_test_pred2 <- knn_fit |>
  augment(new_data = data_test) |>
  # apply the post-processing
  cal_apply(calibrate_knn)


clean <- knn_test_pred2 %>%
  select(.pred, year, week, home_team, away_team, weekly_attendance)
clean$difference <- (clean$.pred-clean$weekly_attendance)
clean %>%
  sort_by(clean$difference)
```

Our test set of 2019 data shows that our model isn't that great at predicting attendance, except for attendance between 60,000 and 80,000. In fact, it seems to be based on luck. Therefore, since our model isn't great at predicting the 2019 data we can't and won't move onto 2020 data until we get better results.

### Limitations and Future Work

The model is poorly predicting games with attendance that don't fall between 60,000 and 80,000 attendants. This is likely due to a majority of values being there for use in k-nearest neighbors, while further values have less similar options. The data collection and analysis would be significantly improved if stadium data were readily available in a precleaned way. In addition, rivalries between teams could be another indicator of attendance. Since I am using a non-parametric approach, the assumptions are satisfied. There are some ethical concerns, such as if there is a great prediction, then teams might hire fewer workers during low attendance games, and ticket prices might be raised on high attendance games.

### Reflection

This project has made me appreciate the difficulty of working with online data and how many of the methods we learned in class have to examined and thought about before being applied to projects.