[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yoav Noiman",
    "section": "",
    "text": "A little bit about me and my life."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Yoav Noiman",
    "section": "Education",
    "text": "Education\nUniversity of California State University, Fullerton | Location | Fall 2021 - Spring 2025"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Yoav Noiman",
    "section": "Experience",
    "text": "Experience\nWorkplace | Job title | April 20XX - present"
  },
  {
    "objectID": "Final_Project_Text_And_Code.html",
    "href": "Final_Project_Text_And_Code.html",
    "title": "Replace this with an interesting title",
    "section": "",
    "text": "This section describes what you are investigating in your project and why you are investigating it. You should provide enough contextual background and information that someone with a limited background can understand the broad outlines of the topic being investigated.\nI am investigating attendance at NFL games because it is interesting to delve into the many factors that play into why a person would go to a stadium rather than simply watch from home. The time of day, date, loyalty to a team, cost, and rivalries may all play a role. There are also other monetary reasons one should consider investigating future attendance. For instance, given a predicted increase, which isn’t possible due to stadium limitations, renovating stadiums for additional seats may become a priority. In addition, there are dynamic reasons, such as ticket prices and the number of staff, which can change depending on predicted attendance.\nThe background to understand NFL game attendance is the locations of stadiums and the popularity of teams. While how the game is played is interesting, it isn’t vital to the analysis as long as we know that higher scores are better. There is, however, a simple rating system where 0 is an average team, with above zero being better and below being worse, used to measure the quality of the teams’ offense, defense, and opponents. There is also a bye week for each team where they don’t play, and the data uses the outdated sixteen-game season with eight played at home and the other eight played away. Lastly, changes in team names and locations are important to consider."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blog/first-post/index.html",
    "href": "blog/first-post/index.html",
    "title": "First Post",
    "section": "",
    "text": "Sed risus ultricies tristique nulla aliquet. Neque volutpat ac tincidunt vitae semper quis lectus nulla.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Enim sed faucibus turpis in eu mi bibendum neque. Ac orci phasellus egestas tellus rutrum tellus pellentesque eu. Velit sed ullamcorper morbi tincidunt ornare massa. Sagittis id consectetur purus ut faucibus pulvinar elementum integer. Tincidunt nunc pulvinar sapien et ligula ullamcorper malesuada proin libero. Lobortis feugiat vivamus at augue eget arcu. Aliquam ut porttitor leo a diam sollicitudin tempor id eu. Mauris a diam maecenas sed enim ut sem viverra aliquet. Enim ut tellus elementum sagittis vitae et leo duis. Molestie at elementum eu facilisis sed odio morbi quis commodo. Sapien pellentesque habitant morbi tristique senectus. Quam vulputate dignissim suspendisse in est. Nulla pellentesque dignissim enim sit amet venenatis urna cursus eget.\nVelit aliquet sagittis id consectetur purus ut faucibus pulvinar elementum. Viverra mauris in aliquam sem fringilla ut morbi tincidunt augue. Tortor at auctor urna nunc id. Sit amet consectetur adipiscing elit duis tristique sollicitudin. Aliquet nibh praesent tristique magna sit amet purus. Tristique senectus et netus et malesuada fames ac turpis. Hac habitasse platea dictumst quisque. Auctor neque vitae tempus quam pellentesque nec nam aliquam. Ultrices tincidunt arcu non sodales neque sodales ut etiam. Iaculis at erat pellentesque adipiscing. Cras tincidunt lobortis feugiat vivamus. Nisi est sit amet facilisis magna etiam. Pharetra pharetra massa massa ultricies mi quis hendrerit. Vitae sapien pellentesque habitant morbi tristique senectus. Ornare aenean euismod elementum nisi quis eleifend quam adipiscing vitae."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Predicting House Prices with Machine Learning\n\n\n\nPython\n\n\nMachine Learning\n\n\nData Cleaning\n\n\n\nThis project involves using machine learning algorithms to predict house prices based on various features such as location, size, and amenities. It includes data cleaning, feature engineering, and model selection.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomer Segmentation Using Clustering Techniques\n\n\n\nR\n\n\nMachine Learning\n\n\nClustering\n\n\nStatistical Modelling\n\n\n\nThis project focuses on segmenting customers into different groups based on their purchasing behavior and demographics. It uses clustering algorithms like K-means and hierarchical clustering to identify distinct customer segments.\n\n\n\nApr 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Global CO2 Emissions\n\n\n\nR\n\n\nData Visualization\n\n\nEnvironmental Science\n\n\n\nThis project involves creating visualizations to show trends in global CO2 emissions over time. It includes data extraction from public databases, data cleaning, and using visualization libraries to create interactive charts and graphs.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/third-post/index.html",
    "href": "blog/third-post/index.html",
    "title": "Third Blog Post",
    "section": "",
    "text": "The source for any page in your website could also be a Jupyter Notebook. This one is third-post/index.ipynb.\nHere’s an example I borrowed from the Seaborn docs:\n\nimport seaborn as sns\n\nsns.set_theme(style=\"whitegrid\")\n\n# Load the diamonds dataset\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Plot the distribution of clarity ratings, conditional on carat\nsns.displot(\n    data=diamonds,\n    x=\"carat\", hue=\"cut\",\n    kind=\"kde\", height=4, aspect=1.5,\n    multiple=\"fill\", clip=(0, None),\n    palette=\"ch:rot=-.25,hue=1,light=.75\",   \n)"
  },
  {
    "objectID": "blog/second-post/index.html",
    "href": "blog/second-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Quis imperdiet massa tincidunt nunc pulvinar sapien et ligula. Amet cursus sit amet dictum sit amet. Eget duis at tellus at urna condimentum. Convallis aenean et tortor at risus viverra. Tincidunt ornare massa eget egestas purus viverra accumsan. Et malesuada fames ac turpis egestas. At imperdiet dui accumsan sit amet. Ut ornare lectus sit amet est placerat. Enim nulla aliquet porttitor lacus luctus accumsan tortor posuere. Duis ultricies lacus sed turpis tincidunt id aliquet risus. Mattis enim ut tellus elementum sagittis. Dui id ornare arcu odio ut. Natoque penatibus et magnis dis. Libero justo laoreet sit amet cursus sit. Sed faucibus turpis in eu. Tempus iaculis urna id volutpat lacus laoreet.\nPhasellus vestibulum lorem sed risus. Eget felis eget nunc lobortis mattis. Sit amet aliquam id diam maecenas ultricies. Egestas maecenas pharetra convallis posuere morbi. Etiam erat velit scelerisque in dictum non consectetur a erat. Cras fermentum odio eu feugiat pretium nibh ipsum consequat. Viverra accumsan in nisl nisi scelerisque. Et netus et malesuada fames ac. Amet tellus cras adipiscing enim eu turpis egestas pretium aenean. Eget lorem dolor sed viverra ipsum nunc aliquet. Ultrices dui sapien eget mi proin sed libero enim sed. Ultricies mi eget mauris pharetra et ultrices neque. Ipsum suspendisse ultrices gravida dictum. A arcu cursus vitae congue mauris rhoncus aenean vel. Gravida arcu ac tortor dignissim convallis. Nulla posuere sollicitudin aliquam ultrices."
  },
  {
    "objectID": "Final_Project_Text_And_Code.html#main-objective",
    "href": "Final_Project_Text_And_Code.html#main-objective",
    "title": "Replace this with an interesting title",
    "section": "Main Objective",
    "text": "Main Objective\nThe main objective of this project is to predict what the attendance per game would have been in the 2020 season if there wasn’t a COVID-19 restriction."
  },
  {
    "objectID": "Final_Project_Text_And_Code.html#packages-used-in-this-analysis",
    "href": "Final_Project_Text_And_Code.html#packages-used-in-this-analysis",
    "title": "Replace this with an interesting title",
    "section": "Packages Used In This Analysis",
    "text": "Packages Used In This Analysis\n\nlibrary(readr)\nlibrary(stringr)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(kknn)\nlibrary(probably)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(workflows)\nlibrary(workflowsets)\nlibrary(recipes)\nlibrary(rsample)\nlibrary(parsnip)\nlibrary(yardstick)\nlibrary(tune)\nlibrary(ggplot2)\nlibrary(tidymodels)\nlibrary(naniar)\n\n\n\n\nPackage\nUse\n\n\n\n\nhere\nto easily load and save data\n\n\nreadr\nto import the CSV file data\n\n\ndplyr\nto massage and summarize data\n\n\nrsample\nto split data into training and test sets\n\n\nggplot2\nto create nice-looking and informative graphs\n\n\n\nFINISH"
  },
  {
    "objectID": "Final_Project_Text_And_Code.html#data-description",
    "href": "Final_Project_Text_And_Code.html#data-description",
    "title": "Replace this with an interesting title",
    "section": "Data Description",
    "text": "Data Description\nI am using data on attendance, scores, and other metrics for football teams’ games from 2000 to 2019. It is from a Tidy Tuesday from 02/04/2020, which is a community which posts weekly projects. The data is collected from Pro Football Reference which I am also using, and it was most likely collected through nfl.com as there is a game book which states the attendance as the data matches it. It also states the stadiums which would be useful to scrape and the dates and times are also most likely collected from their. The game book states it is paid attendance which is probably collected based on how many tickets are used to enter the stadium.\nTidy Tuesday https://github.com/rfordatascience/tidytuesday/tree/main/data/2020/2020-02-04\nPro Football Reference https://www.pro-football-reference.com/\nNFL Website https://www.nfl.com/\n\nattendance &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/attendance.csv')\nstandings &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/standings.csv')\ngames &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/games.csv')\n\nstadiums &lt;- clean_names(read_excel(here::here(\"Final_Project_Data/Stadiums.xls\")))\n\nAttendance_2020 &lt;- clean_names(read_excel(here::here(\"Final_Project_Data/2020Attendance.xls\")))\n\n\nData Limitations\nThere are many limitations, such as there not being recorded stadiums, stadium capacity, and the size of the city. There may also be bias in the way that attendance is recorded to make the league seem to have a better performance or for headlines. The methodology that follows also may not be applicable to other sports as the number of games may be vital to whether people attend a game, whether due to fatigue from too many games or better opportunities; however, due to similarities, college football may be applicable. In addition, preseason and playoff data aren’t included; however, the methodology that follows may be applicable to them."
  },
  {
    "objectID": "Final_Project_Text_And_Code.html#data-wrangling-optional-section",
    "href": "Final_Project_Text_And_Code.html#data-wrangling-optional-section",
    "title": "Replace this with an interesting title",
    "section": "Data Wrangling (Optional Section)",
    "text": "Data Wrangling (Optional Section)\n\nAttendance_2020 &lt;- Attendance_2020 %&gt;%\n  mutate(across(starts_with(\"week_\"), as.numeric)) %&gt;%\n  pivot_longer(\n    cols = starts_with(\"week_\"),\n    names_prefix = \"week_\",\n    names_to = \"week\",\n    values_to = \"weekly_attendance\"\n  )\n\nWarning: There were 9 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `across(starts_with(\"week_\"), as.numeric)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 8 remaining warnings.\n\nattendance$newteam &lt;- str_c(attendance$team, attendance$team_name, sep = \" \", collapse = NULL)\nstandings$newteam &lt;- str_c(standings$team, standings$team_name, sep = \" \", collapse = NULL)\ngames$week &lt;- as.numeric(games$week)\n\nWarning: NAs introduced by coercion\n\ngames &lt;- games %&gt;%\n  drop_na(week)\ndata &lt;- games %&gt;%\n  left_join(attendance, by = c(\"home_team\" = \"newteam\", \"year\", \"week\"))\ndata &lt;- data %&gt;%\n  left_join(standings, by = c(\"home_team\" = \"newteam\", \"year\", \"team\", \"team_name\"))\nstadiums &lt;- stadiums %&gt;%\n  separate_rows(primary_team_s, sep = \",\")\nstadiums &lt;- stadiums %&gt;%\n  drop_na(primary_team_s)\nstadiums &lt;- stadiums %&gt;%\n  rowwise() %&gt;%\n  mutate(year = list(from:to)) %&gt;%\n  unnest(year) %&gt;%\n  select(-from, -to)\nstadiums &lt;- stadiums %&gt;%\n  filter(year &gt;= 2000)\nstadiums &lt;- stadiums %&gt;%\n  filter(year &lt;= 2020)\nstadiums &lt;- stadiums %&gt;%\n  distinct(year, primary_team_s, .keep_all = TRUE)\ndata &lt;- data %&gt;%\n  left_join(stadiums, by = c(\"home_team\" = \"primary_team_s\", \"year\"))\n\n\ndata_train &lt;- data %&gt;%\n  filter(year != 2019)\ndata_test &lt;- data %&gt;%\n  filter(year == 2019)"
  },
  {
    "objectID": "Final_Project_Text_And_Code.html#exploratory-data-analysis",
    "href": "Final_Project_Text_And_Code.html#exploratory-data-analysis",
    "title": "Replace this with an interesting title",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nattendance %&gt;%\n  miss_var_summary()\n\n# A tibble: 9 × 3\n  variable          n_miss pct_miss\n  &lt;chr&gt;              &lt;int&gt;    &lt;num&gt;\n1 weekly_attendance    638     5.88\n2 team                   0     0   \n3 team_name              0     0   \n4 year                   0     0   \n5 total                  0     0   \n6 home                   0     0   \n7 away                   0     0   \n8 week                   0     0   \n9 newteam                0     0   \n\ncount(attendance)/638\n\n   n\n1 17\n\n\nThis corresponds one-to-one to the fact that each team is given one week of the seventeen-week season as a bye week.\n\ndata_train %&gt;%\nsummarize(\nnumber = n(),\nweekly_attendance_mean = mean(weekly_attendance, na.rm = TRUE),\nweekly_attendance_sd = sd(weekly_attendance, na.rm = TRUE),\nweekly_attendance_min = min(weekly_attendance, na.rm = TRUE),\nweekly_attendance_q1 = quantile(weekly_attendance, 0.25, na.rm = TRUE),\nweekly_attendance_median = median(weekly_attendance, na.rm = TRUE),\nweekly_attendance_q3 = quantile(weekly_attendance, 0.75, na.rm = TRUE),\nweekly_attendance_max = max(weekly_attendance, na.rm = TRUE)\n)\n\n# A tibble: 1 × 8\n  number weekly_attendance_mean weekly_attendance_sd weekly_attendance_min\n   &lt;int&gt;                  &lt;dbl&gt;                &lt;dbl&gt;                 &lt;dbl&gt;\n1   4848                 67609.                8897.                 23127\n# ℹ 4 more variables: weekly_attendance_q1 &lt;dbl&gt;,\n#   weekly_attendance_median &lt;dbl&gt;, weekly_attendance_q3 &lt;dbl&gt;,\n#   weekly_attendance_max &lt;dbl&gt;\n\nggplot(data = data_train,\n       mapping = aes(x = weekly_attendance)\n) +\n  geom_histogram(center = 57500,\n                 binwidth = 5000)\n\n\n\n\n\n\n\nggplot(data = data_train,\nmapping = aes(y = weekly_attendance)\n) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\nThrough the table, we can get the total number of values, mean, standard deviation, minimum, median, maximum, and the value at the \\(25\\%\\) and \\(75%\\) of attendance in training data. Through the exact values, we notice that attendance is centered between 63,000 and 73,000 people. In addition, all the values are plausible, as there are no recorded negative or exceedingly high values. The histogram shows no large breaks between different recorded attendances, but as the values get more extreme, there are fewer recorded games with such attendance. The boxplot shows a large number of outliers."
  },
  {
    "objectID": "Final_Project_Text_And_Code.html#modeling",
    "href": "Final_Project_Text_And_Code.html#modeling",
    "title": "Replace this with an interesting title",
    "section": "Modeling",
    "text": "Modeling\n\nlm1 &lt;- lm(weekly_attendance ~ home_team + away_team + week + year, data = data_train)\nsummary(lm1)\n\n\nCall:\nlm(formula = weekly_attendance ~ home_team + away_team + week + \n    year, data = data_train)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-37285  -1534    484   2609  55136 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   -179456.19   31012.48  -5.787 7.64e-09 ***\nhome_teamAtlanta Falcons        11795.95     666.82  17.690  &lt; 2e-16 ***\nhome_teamBaltimore Ravens       14299.53     672.91  21.250  &lt; 2e-16 ***\nhome_teamBuffalo Bills          10802.96     672.73  16.058  &lt; 2e-16 ***\nhome_teamCarolina Panthers      16866.56     667.07  25.285  &lt; 2e-16 ***\nhome_teamChicago Bears           5777.62     666.50   8.669  &lt; 2e-16 ***\nhome_teamCincinnati Bengals      3853.27     672.82   5.727 1.08e-08 ***\nhome_teamCleveland Browns       13239.40     672.67  19.682  &lt; 2e-16 ***\nhome_teamDallas Cowboys         21062.68     666.14  31.619  &lt; 2e-16 ***\nhome_teamDenver Broncos         19719.57     671.56  29.364  &lt; 2e-16 ***\nhome_teamDetroit Lions           5729.20     668.62   8.569  &lt; 2e-16 ***\nhome_teamGreen Bay Packers      15056.33     666.59  22.587  &lt; 2e-16 ***\nhome_teamHouston Texans         14774.89     691.62  21.363  &lt; 2e-16 ***\nhome_teamIndianapolis Colts      5528.90     671.90   8.229 2.42e-16 ***\nhome_teamJacksonville Jaguars    6598.97     672.32   9.815  &lt; 2e-16 ***\nhome_teamKansas City Chiefs     18480.72     671.56  27.519  &lt; 2e-16 ***\nhome_teamLos Angeles Chargers  -28119.00    1521.98 -18.475  &lt; 2e-16 ***\nhome_teamLos Angeles Rams       16010.63    1271.88  12.588  &lt; 2e-16 ***\nhome_teamMiami Dolphins         12149.08     672.88  18.055  &lt; 2e-16 ***\nhome_teamMinnesota Vikings       6295.67     667.72   9.429  &lt; 2e-16 ***\nhome_teamNew England Patriots   11041.24     672.95  16.407  &lt; 2e-16 ***\nhome_teamNew Orleans Saints     13352.03     666.17  20.043  &lt; 2e-16 ***\nhome_teamNew York Giants        22290.94     665.98  33.471  &lt; 2e-16 ***\nhome_teamNew York Jets          21549.60     672.58  32.040  &lt; 2e-16 ***\nhome_teamOakland Raiders         -951.57     671.52  -1.417 0.156539    \nhome_teamPhiladelphia Eagles    12034.77     666.60  18.054  &lt; 2e-16 ***\nhome_teamPittsburgh Steelers     5945.32     672.78   8.837  &lt; 2e-16 ***\nhome_teamSan Diego Chargers      7037.28     690.10  10.198  &lt; 2e-16 ***\nhome_teamSan Francisco 49ers    12606.11     663.40  19.002  &lt; 2e-16 ***\nhome_teamSeattle Seahawks       10638.91     663.34  16.038  &lt; 2e-16 ***\nhome_teamSt. Louis Rams          4982.99     693.68   7.183 7.85e-13 ***\nhome_teamTampa Bay Buccaneers    5458.02     666.00   8.195 3.18e-16 ***\nhome_teamTennessee Titans       11894.06     672.32  17.691  &lt; 2e-16 ***\nhome_teamWashington Redskins    24135.29     666.59  36.207  &lt; 2e-16 ***\naway_teamAtlanta Falcons          970.50     667.23   1.455 0.145869    \naway_teamBaltimore Ravens         929.84     673.23   1.381 0.167292    \naway_teamBuffalo Bills            679.67     672.76   1.010 0.312421    \naway_teamCarolina Panthers         63.31     667.65   0.095 0.924452    \naway_teamChicago Bears           1959.14     667.02   2.937 0.003328 ** \naway_teamCincinnati Bengals       323.28     673.28   0.480 0.631140    \naway_teamCleveland Browns         406.39     673.35   0.604 0.546176    \naway_teamDallas Cowboys          3158.48     666.80   4.737 2.23e-06 ***\naway_teamDenver Broncos          2195.38     671.65   3.269 0.001088 ** \naway_teamDetroit Lions           1269.47     669.01   1.898 0.057818 .  \naway_teamGreen Bay Packers       2843.77     666.80   4.265 2.04e-05 ***\naway_teamHouston Texans           -12.39     691.72  -0.018 0.985705    \naway_teamIndianapolis Colts      1562.14     671.76   2.325 0.020091 *  \naway_teamJacksonville Jaguars    -154.30     672.74  -0.229 0.818598    \naway_teamKansas City Chiefs       506.81     671.49   0.755 0.450441    \naway_teamLos Angeles Chargers     717.78    1522.28   0.472 0.637295    \naway_teamLos Angeles Rams        1158.26    1271.70   0.911 0.362448    \naway_teamMiami Dolphins          1623.40     672.49   2.414 0.015815 *  \naway_teamMinnesota Vikings       1570.97     667.93   2.352 0.018713 *  \naway_teamNew England Patriots    2932.91     673.52   4.355 1.36e-05 ***\naway_teamNew Orleans Saints      1036.38     666.55   1.555 0.120050    \naway_teamNew York Giants         1342.50     666.38   2.015 0.044001 *  \naway_teamNew York Jets           1500.36     673.53   2.228 0.025952 *  \naway_teamOakland Raiders         1654.57     671.86   2.463 0.013826 *  \naway_teamPhiladelphia Eagles     1576.65     666.68   2.365 0.018073 *  \naway_teamPittsburgh Steelers     2920.99     673.48   4.337 1.47e-05 ***\naway_teamSan Diego Chargers       891.14     690.68   1.290 0.197031    \naway_teamSan Francisco 49ers     1449.68     663.80   2.184 0.029018 *  \naway_teamSeattle Seahawks         804.63     663.52   1.213 0.225322    \naway_teamSt. Louis Rams           620.09     693.50   0.894 0.371283    \naway_teamTampa Bay Buccaneers     869.28     666.30   1.305 0.192081    \naway_teamTennessee Titans        1027.05     672.39   1.527 0.126712    \naway_teamWashington Redskins      641.14     666.73   0.962 0.336294    \nweek                              -62.41      16.55  -3.772 0.000164 ***\nyear                              117.02      15.43   7.583 4.05e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5741 on 4779 degrees of freedom\nMultiple R-squared:  0.5895,    Adjusted R-squared:  0.5837 \nF-statistic: 100.9 on 68 and 4779 DF,  p-value: &lt; 2.2e-16\n\nplot(lm1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlinreg_model &lt;- linear_reg(mode = \"regression\", engine = \"lm\")\nknn_model &lt;- nearest_neighbor(mode = \"regression\",\n                              engine = \"kknn\",\n                              neighbors = 8, dist_power = 2)\n\nlinear_recipe &lt;- recipe(\n  weekly_attendance ~ home_team + away_team + week + year, # response ~ predictors\n  data = data_train\n)\n\nquadratic_recipe &lt;- recipe(\n  weekly_attendance ~ home_team + away_team + week + year, # response ~ predictors\n  data = data_train\n) |&gt;\n  step_poly(week, degree = 2)\n\ninteraction_recipe &lt;- recipe(\n  weekly_attendance ~ home_team + away_team + week + year, # response ~ predictors\n  data = data_train\n) |&gt;\n  step_interact(terms = ~week:year) # add HR:BB interaction term\n\nknn_recipe &lt;- recipe(\n  weekly_attendance ~ home_team + away_team + week + year,\n  data = data_train\n) |&gt;\n  step_normalize(all_numeric_predictors()) |&gt;\n  step_dummy(all_nominal_predictors())\n\nall_models &lt;- workflow_set(\n  preproc = list(linear = linear_recipe, quadratic = quadratic_recipe,\n                 interaction = interaction_recipe, knn = knn_recipe),\n  models = list(lr = linreg_model, lr = linreg_model,\n                lr = linreg_model, knn = knn_model),\n  cross = FALSE # don't mix knn recipes with linear models or vice-versa\n)\nall_models\n\n# A workflow set/tibble: 4 × 4\n  wflow_id       info             option    result    \n  &lt;chr&gt;          &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 linear_lr      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 quadratic_lr   &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n3 interaction_lr &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 knn_knn        &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n\nset.seed(1112)\ndata_cv &lt;- vfold_cv(data_train, v = 10)\n\nall_models &lt;- all_models |&gt;\n  workflow_map(\"fit_resamples\",\n               resamples = data_cv,\n               metrics = metric_set(rmse, mae),\n               verbose = TRUE) # lets you know where you are in the fitting process\n\ni 1 of 4 resampling: linear_lr\n\n\n✔ 1 of 4 resampling: linear_lr (385ms)\n\n\ni 2 of 4 resampling: quadratic_lr\n\n\n✔ 2 of 4 resampling: quadratic_lr (430ms)\n\n\ni 3 of 4 resampling: interaction_lr\n\n\n✔ 3 of 4 resampling: interaction_lr (399ms)\n\n\ni 4 of 4 resampling: knn_knn\n\n\n✔ 4 of 4 resampling: knn_knn (13.7s)\n\nknn_model2 &lt;- nearest_neighbor(mode = \"regression\", \n                               engine = \"kknn\",\n                               neighbors = tune(), \n                               dist_power = 2)\n\nknn.grid &lt;- expand.grid(neighbors = seq(1,20, by = 1))\n\nall_models2 &lt;- workflow_set(\n  preproc = list(linear = linear_recipe, \n                 quadratic = quadratic_recipe,\n                 interaction = interaction_recipe, \n                 knn = knn_recipe),\n  models = list(lr = linreg_model, \n                lr = linreg_model,\n                lr = linreg_model,\n                knn2 = knn_model2),\n  cross = FALSE \n)\n\nall_models2 &lt;- all_models2 |&gt;\n  # add the grid for JUST the knn model\n  option_add(grid = knn.grid, id = \"knn_knn2\") |&gt;\n  workflow_map(\"tune_grid\",\n               resamples = data_cv,\n               metrics = metric_set(rmse), # can add more\n               verbose = TRUE)\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 1 of 4 resampling: linear_lr\n\n\n✔ 1 of 4 resampling: linear_lr (432ms)\n\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 2 of 4 resampling: quadratic_lr\n\n\n✔ 2 of 4 resampling: quadratic_lr (429ms)\n\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 3 of 4 resampling: interaction_lr\n\n\n✔ 3 of 4 resampling: interaction_lr (554ms)\n\n\ni 4 of 4 tuning:     knn_knn2\n\n\n✔ 4 of 4 tuning:     knn_knn2 (41.8s)\n\nautoplot(all_models2)\n\n\n\n\n\n\n\nautoplot(all_models2, id = \"knn_knn2\")\n\n\n\n\n\n\n\nrank_results(all_models2) |&gt;\n  dplyr::select(wflow_id, .config, .metric, mean, std_err, rank) |&gt;\n  arrange(.metric, rank)\n\n# A tibble: 23 × 6\n   wflow_id       .config               .metric  mean std_err  rank\n   &lt;chr&gt;          &lt;chr&gt;                 &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;\n 1 linear_lr      Preprocessor1_Model1  rmse    5785.    161.     1\n 2 quadratic_lr   Preprocessor1_Model1  rmse    5786.    162.     2\n 3 interaction_lr Preprocessor1_Model1  rmse    5787.    161.     3\n 4 knn_knn2       Preprocessor1_Model06 rmse    6526.    197.     4\n 5 knn_knn2       Preprocessor1_Model05 rmse    6535.    198.     5\n 6 knn_knn2       Preprocessor1_Model07 rmse    6542.    196.     6\n 7 knn_knn2       Preprocessor1_Model08 rmse    6569.    194.     7\n 8 knn_knn2       Preprocessor1_Model04 rmse    6582.    199.     8\n 9 knn_knn2       Preprocessor1_Model09 rmse    6594.    191.     9\n10 knn_knn2       Preprocessor1_Model10 rmse    6616.    188.    10\n# ℹ 13 more rows\n\nbest_k &lt;- all_models2 |&gt; \n  extract_workflow_set_result(id = \"knn_knn2\") |&gt; \n  select_best(metric = \"rmse\")\n  \nmy_best_knn &lt;- all_models2 |&gt;\n  extract_workflow(\"knn_knn2\") |&gt;\n  finalize_workflow(parameters = best_k)\n\nmy_best_knn\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: nearest_neighbor()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nK-Nearest Neighbor Model Specification (regression)\n\nMain Arguments:\n  neighbors = 6\n  dist_power = 2\n\nComputational engine: kknn \n\n\n\nbest_model_refit &lt;- my_best_knn |&gt;\n  fit_resamples(\n    resamples = data_cv,\n    # save the cross-validated predictions\n    control = control_resamples(save_pred = TRUE)\n)\n\npredictions_best_model &lt;- best_model_refit |&gt;\n  collect_predictions()\n\ncal_plot_regression(\n  predictions_best_model,\n  truth = weekly_attendance,\n  estimate = .pred\n)\n\n\n\n\n\n\n\nbest_model_refit |&gt;\n  cal_validate_linear(\n    save_pred = TRUE,\n    smooth = TRUE) |&gt; # nonlinear smoothing, use smooth = FALSE for linear transformation\n  collect_predictions() |&gt;\n  cal_plot_regression(\n    truth = weekly_attendance,\n    estimate = .pred\n  )\n\n\n\n\n\n\n\ncalibrate_knn &lt;- predictions_best_model |&gt;\n  # instructions for post-processing\n  cal_estimate_linear(\n    truth = weekly_attendance,\n    smooth = TRUE # nonlinear smoothing\n  )\n\nknn_fit &lt;- my_best_knn |&gt; fit(\n  data = data_train\n)\n\nknn_test_pred2 &lt;- knn_fit |&gt;\n  augment(new_data = data_test) |&gt;\n  # apply the post-processing\n  cal_apply(calibrate_knn)\n\nknn_test_pred2\n\n# A tibble: 256 × 43\n    .pred  .resid  year  week home_team away_team winner tie   day   date  time \n    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;tim&gt;\n 1 63164.  2.58e2  2019     1 Chicago … Green Ba… Green… &lt;NA&gt;  Thu   Sept… 20:20\n 2 66532.  1.34e3  2019     1 Clevelan… Tennesse… Tenne… &lt;NA&gt;  Sun   Sept… 13:00\n 3 60690.  8.46e3  2019     1 Minnesot… Atlanta … Minne… &lt;NA&gt;  Sun   Sept… 13:00\n 4 69544.  3.09e2  2019     1 Philadel… Washingt… Phila… &lt;NA&gt;  Sun   Sept… 13:00\n 5 64209.  8.60e3  2019     1 Carolina… Los Ange… Los A… &lt;NA&gt;  Sun   Sept… 13:00\n 6 78133.  7.92e2  2019     1 New York… Buffalo … Buffa… &lt;NA&gt;  Sun   Sept… 13:00\n 7 60060.  3.60e3  2019     1 Jacksonv… Kansas C… Kansa… &lt;NA&gt;  Sun   Sept… 13:00\n 8 67733. -2.47e3  2019     1 Miami Do… Baltimor… Balti… &lt;NA&gt;  Sun   Sept… 13:00\n 9 28264.  5.32e0  2019     1 Los Ange… Indianap… Los A… &lt;NA&gt;  Sun   Sept… 16:05\n10 67214.  1.82e3  2019     1 Seattle … Cincinna… Seatt… &lt;NA&gt;  Sun   Sept… 16:05\n# ℹ 246 more rows\n# ℹ 32 more variables: pts_win &lt;dbl&gt;, pts_loss &lt;dbl&gt;, yds_win &lt;dbl&gt;,\n#   turnovers_win &lt;dbl&gt;, yds_loss &lt;dbl&gt;, turnovers_loss &lt;dbl&gt;,\n#   home_team_name &lt;chr&gt;, home_team_city &lt;chr&gt;, away_team_name &lt;chr&gt;,\n#   away_team_city &lt;chr&gt;, team &lt;chr&gt;, team_name &lt;chr&gt;, total &lt;dbl&gt;, home &lt;dbl&gt;,\n#   away &lt;dbl&gt;, weekly_attendance &lt;dbl&gt;, wins &lt;dbl&gt;, loss &lt;dbl&gt;,\n#   points_for &lt;dbl&gt;, points_against &lt;dbl&gt;, points_differential &lt;dbl&gt;, …\n\n\n\ntreeR_model &lt;- decision_tree(mode = \"regression\", engine = \"rpart\",\n                          cost_complexity = tune())\n\ntreeR_recipe &lt;- recipe(\n  weekly_attendance ~ home_team + away_team + week + year, # response ~ predictors\n  data = data_train\n)\n\ntreeR_wflow &lt;- workflow() |&gt;\n  add_model(treeR_model) |&gt;\n  add_recipe(treeR_recipe)\n\ndata_kfold &lt;- vfold_cv(data_train, v = 5, repeats = 3) \n\ntreeR_tune1 &lt;- tune_grid(treeR_model, \n                      treeR_recipe, \n                      resamples = data_kfold, \n                      metrics = metric_set(rmse), # ignore r-squared, we get warning messages\n                      grid = grid_regular(cost_complexity(range = c(-3, 0)), levels = 10))\n\ntreeR_tune1 |&gt;\n  collect_metrics() |&gt; # no need to filter for RMSE because it's the only one \n  ggplot(mapping = aes(x = cost_complexity, y = mean)) + \n  geom_point() + \n  geom_line() +\n  scale_x_log10()\n\n\n\n\n\n\n\ntreeR_best &lt;- select_by_one_std_err(\n  treeR_tune1,\n  metric = \"rmse\",\n  desc(cost_complexity)\n)\ntreeR_best\n\n# A tibble: 1 × 2\n  cost_complexity .config              \n            &lt;dbl&gt; &lt;chr&gt;                \n1           0.001 Preprocessor1_Model01\n\ntreeR_wflow_final &lt;- finalize_workflow(treeR_wflow, parameters = treeR_best) \n\ntreeR_pred_check &lt;- treeR_wflow_final |&gt;\n  fit_resamples(\n    resamples = data_kfold,\n    # save the cross-validated predictions\n    control = control_resamples(save_pred = TRUE)\n) |&gt; \n  collect_predictions()\n\nggplot(treeR_pred_check, aes(x = weekly_attendance, y = .pred)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, color = \"blue\")"
  },
  {
    "objectID": "Final_Project_Text_And_Code.html#insights",
    "href": "Final_Project_Text_And_Code.html#insights",
    "title": "Replace this with an interesting title",
    "section": "Insights",
    "text": "Insights\n\nLimitations and Future Work\n\n\nReflection (Optional Subsection)"
  },
  {
    "objectID": "Final_Project_Text_And_Code.html#motivation-and-context",
    "href": "Final_Project_Text_And_Code.html#motivation-and-context",
    "title": "Replace this with an interesting title",
    "section": "",
    "text": "This section describes what you are investigating in your project and why you are investigating it. You should provide enough contextual background and information that someone with a limited background can understand the broad outlines of the topic being investigated.\nI am investigating attendance at NFL games because it is interesting to delve into the many factors that play into why a person would go to a stadium rather than simply watch from home. The time of day, date, loyalty to a team, cost, and rivalries may all play a role. There are also other monetary reasons one should consider investigating future attendance. For instance, given a predicted increase, which isn’t possible due to stadium limitations, renovating stadiums for additional seats may become a priority. In addition, there are dynamic reasons, such as ticket prices and the number of staff, which can change depending on predicted attendance.\nThe background to understand NFL game attendance is the locations of stadiums and the popularity of teams. While how the game is played is interesting, it isn’t vital to the analysis as long as we know that higher scores are better. There is, however, a simple rating system where 0 is an average team, with above zero being better and below being worse, used to measure the quality of the teams’ offense, defense, and opponents. There is also a bye week for each team where they don’t play, and the data uses the outdated sixteen-game season with eight played at home and the other eight played away. Lastly, changes in team names and locations are important to consider."
  }
]